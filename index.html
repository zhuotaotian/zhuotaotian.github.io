<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Zhuotao Tian, The Chinese University of Hong Kong">
    <meta name="description" content="Zhuotao Tian's home page">
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <title>Zhuotao Tian</title>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39824124-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script');
        ga.type = 'text/javascript';
        ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(ga, s);
    })();
    </script>
</head>

<body>
<div id="layout-content" style="margin-top:25px">
<table>
    <tbody>
        <tr>
        	<td width="670">
                <div id="toptitle">
                    <h1>Zhuotao Tian</h1>
				</div>
				<h3>
					Professor </br>
				</h3>
				<p>
					School of Computer Science </br>
					Harbin Institute of Technology (Shenzhen) </br>
					Shenzhen, China</br>
					</br>
					Email: <a href="mailto:tianzhuotao@gmail.com">tianzhuotao [at] gmail [dot] com</a> or <a href="mailto:tianzhuotao@gmail.com">jiangli [at] cuhk [dot] edu [dot] cn</a>
				</p>
				<p>
					<a href="https://github.com/zhuotaotian"><img src="pics/github.png" height="30px"></a>
					<a href="https://scholar.google.com/citations?user=mEjhz-IAAAAJ&hl=zh-CN"><img src="pics/google_scholar.png" height="30px"></a>
				</p>
			</td>
<!-- 			<td><img src="pics/lijiang.jpg" border="0" height="250"></br></td> -->
		<tr>
	</tbody>
</table>

<h2>Biography</h2>
<p>
	<div style="text-align:justify">
	    I am a professor of <a href="https://hitsz.edu.cn/">Harbin Institute of Technology, Shenzhen (HIT-SZ)</a>.
	    Previously, I was a senior researcher in <a href="https://global.smartmore.com/">SmartMore (Hong Kong)</a>,
		working with <a href="https://scholar.google.com/citations?user=BUEDUFkAAAAJ&hl=zh-CN">Dr. Shu Liu</a>. 
		I obtained my Ph.D. degree in <a href="http://www.cse.cuhk.edu.hk">Computer Science and Engineering Department</a>, 
		<a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong (CUHK)</a>, 
		supervised by <a href="http://www.cse.cuhk.edu.hk/~leojia">Prof. Jiaya Jia</a> and <a href="https://www.cse.cuhk.edu.hk/~byu/">Prof. Bei Yu</a>. 
		Before that, I received the B.E. degree from <a href = "http://www.hit.edu.cn">Harbin Institute of Technology (HIT)</a> in 2018. 
		I was selected for the Excellent Young Scientists Fund Program (Overseas)（国家级高层次青年人才）.
	</div>
</p>

<p><font color="red">I am looking for self-motivated PhD students (2026), posdoctoral researchers, and research assistant. If you are interested in working with me, please drop me an email with your resume.</font></p>

<p>My research interest includes computer vision and artificial intelligence. Our current research interest and focus include scene understanding, multi-modal perception, large language models (LLMs), efficient learning and embodied AI. </p>

<h2>Selected Publications [<a href="https://scholar.google.com/citations?user=mEjhz-IAAAAJ&hl=zh-CN">Google Scholar</a>]</h2>
<ul>
	* indicates equal contribution; † indicates corresponding author.
	<!-- <li>
		<a href=""></a><br>
		.<br>
		<em></em> <br>
		<p style="margin-top:3px">
			[<a href="">Paper</a>]
			[<a href="">Code</a>]
			[<a href="">Bib</a>]
		</p>
	</li> -->
	<li>
		<a href="https://arxiv.org/abs/2507.12455">Mitigating Object Hallucinations via Sentence-Level Early Intervention</a><br>
		Shangpin Peng, Senqiao Yang, Li Jiang, <b>Zhuotao Tian†</b> <br>
		<em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2025.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2507.12455">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2506.10507">Edit360: 2D Image Edits to 3D Assets from Any Angle</a><br>
		Junchao Huang, Xinting Hu, <b>Zhuotao Tian</b>, Shaoshuai Shi, Li Jiang <br>
		<em>IEEE International Conference on Computer Vision</em> (<b>ICCV, Highlight</b>), 2025.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2506.10507">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2506.10054">Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs</a><br>
		Shangpin Peng, Weinong Wang, <b>Zhuotao Tian†</b>, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang <br>
		arXiv preprint arXiv:2506.10054 </br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2506.10054">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://zhuotaotian.github.io/">CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval</a><br>
		Bin Kang, Bin Chen, Junjie Wang, Yulin Li, Junzhi Zhao, Junle Wang, <b>Zhuotao Tian†</b> <br>
		<em>ACM International Conference on Multimedia</em> (<b>ACM MM, Oral</b>), 2025.</br>
		<p style="margin-top:3px">
			[<a href="https://zhuotaotian.github.io/">Paper</a>]
		</p>
	</li>	

	<li>
		<a href="https://arxiv.org/abs/2412.04467">VisionZip: Longer is Better but Not Necessary in Vision Language Models</a><br>
		Senqiao Yang, Yukang Chen, <b>Zhuotao Tian†</b>, Chengyao Wang, Jingyao Li, Bei Yu, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2412.04467">Paper</a>]
		</p>
	</li>	

	<li>
		<a href="https://arxiv.org/abs/2505.04410">DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception</a><br>
		Junjie Wang, Bing Chen, Yulin Li, Bin Kang, Yichi Chen, <b>Zhuotao Tian†</b> <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2025.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2505.04410">Paper</a>]
		</p>
	</li>	

	<li>
		<a href="https://arxiv.org/abs/2411.01981">Typicalness-Aware Learning for Failure Detection</a><br>
		Yijun Liu, Jiequan Cui, <b>Zhuotao Tian†</b>, Senqiao Yang, Qingdong He, Xiaoling Wang, Jingyong Su> <br>
		<em>Conference on Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2411.01981">Paper</a>]
		</p>
	</li>	

	<li>
		<a href="https://arxiv.org/pdf/2406.18629">Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs</a><br>
		Xin Lai, <b>Zhuotao Tian</b>, Yukang Chen, Senqiao Yang, Xiangru Peng, Jiaya Jia <br>
		arXiv preprint arXiv:2406.18629 </br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2406.18629?">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2404.07470">Scalable Language Model with Generalized Continual Learning</a><br>
		Bohao Peng, <b>Zhuotao Tian†</b>, Shu Liu, Mingchang Yang, Jiaya Jia <br>
		<em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2404.07470">Paper</a>]
		</p>
	</li>
	
	<li>
		<a href="https://arxiv.org/abs/2404.07155">Unified Language-driven Zero-shot Domain Adaptation</a><br>
		Senqiao Yang, <b>Zhuotao Tian†</b>, Li Jiang, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2404.07155">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2308.00692">LISA: Reasoning Segmentation via Large Language Model</a><br>
		Xin Lai, <b>Zhuotao Tian†</b>, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR, Oral</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2308.00692">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2312.17240">LISA++: An Improved Baseline for Reasoning Segmentation with Large Language Model</a><br>
		Senqiao Yang, Tianyuan Qu, Xin Lai, <b>Zhuotao Tian†</b>, Bohao Peng, Shu Liu, Jiaya Jia <br>
		arXiv preprint arXiv: 2312.17240 </br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2312.17240">Paper</a>]
		</p>
	</li>
	
	<li>
		<a href="https://arxiv.org/abs/2403.14418">OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation</a><br>
		Bohao Peng, Xiaoyang Wu, Li Jiang, Yukang Chen, Hengshuang Zhao, <b>Zhuotao Tian</b>, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2403.14418">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2403.09639">Groupcontrast: Semantic-aware self-supervised representation learning for 3d understanding</a><br>
		Chengyao Wang, Li Jiang, Xiaoyang Wu, <b>Zhuotao Tian</b>, Bohao Peng, Hengshuang Zhao, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2403.09639">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_SaCo_Loss_Sample-wise_Affinity_Consistency_for_Vision-Language_Pre-training_CVPR_2024_paper.pdf">Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training</a><br>
		Sitong Wu, Haoru Tan, <b>Zhuotao Tian</b>, Yukang Chen, Xiaojuan Qi, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_SaCo_Loss_Sample-wise_Affinity_Consistency_for_Vision-Language_Pre-training_CVPR_2024_paper.pdf">Paper</a>]
		</p>
	</li>
	
	<li>
		<a href="https://arxiv.org/abs/2308.09718">SaCo Loss: Sample-wise Affinity Consistency for Vision-Language Pre-training</a><br>
		Xiaoyang Wu, <b>Zhuotao Tian</b>, Xin Wen, Bohao Peng, Xihui Liu, Kaicheng Yu, Hengshuang Zhao <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2024</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2308.09718">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/pdf/2109.13788">PFENet++: Boosting Few-shot Semantic Segmentation with the Noise-filtered Context-aware Prior Mask</a><br>
		Xiaoliu Luo, <b>Zhuotao Tian*</b>, Taiping Zhang, Bei Yu, Yuan Yan Tang, Jiaya Jia <br>
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2023</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2109.13788">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2303.14652">Hierarchical Dense Correlation Distillation for Few-Shot Segmentation</a><br>
		Bohao Peng, <b>Zhuotao Tian†</b>, Xiaoyang Wu, Chenyao Wang, Shu Liu, Jingyong Su, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2023</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2303.14652">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2303.11633">Learning Context-aware Classifier for Semantic Segmentation</a><br>
		<b>Zhuotao Tian</b>, Jiequan Cui, Li Jiang, Xiaojuan Qi, Xin Lai, Yixin Chen, Shu Liu, Jiaya Jia <br>
		<em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI, Oral</b>), 2023</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2303.11633">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2209.12400">Generalized Parametric Contrastive Learning</a><br>
		Jiequan Cui, Zhisheng Zhong, <b>Zhuotao Tian</b>, Shu Liu, Bei Yu, Jiaya Jia <br>
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2023</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2209.12400">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://ieeexplore.ieee.org/document/9736597">Adaptive Perspective Distillation for Semantic Segmentation</a><br>
		<b>Zhuotao Tian</b>, Pengguang Chen, Xin Lai, Li Jiang, Shu Liu, Hengshuang Zhao, Bei Yu, Ming-Chang Yang, Jiaya Jia <br>
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2023</br>
		<p style="margin-top:3px">
			[<a href="https://ieeexplore.ieee.org/document/9736597">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://ieeexplore.ieee.org/abstract/document/9154595/">Prior Guided Feature Enrichment Network for Few-Shot Segmentation</a><br>
		<b>Zhuotao Tian</b>, Hengshuang Zhao, Michelle Shu, Zhicheng Yang, Ruiyu Li, Jiaya Jia <br>
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2022</br>
		<p style="margin-top:3px">
			[<a href="https://ieeexplore.ieee.org/abstract/document/9154595/">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf">Generalized Few-Shot Semantic Segmentation</a><br>
		<b>Zhuotao Tian</b>, Xin Lai, Li Jiang, Shu Liu, Michelle Shu, Hengshuang Zhao, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022</br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2110.08188">Generalized Few-Shot Semantic Segmentation</a><br>
		Li Jiang, Shaoshuai Shi, <b>Zhuotao Tian</b>, Xin Lai, Shu Liu, Chi-Wing Fu, Jiaya Jia <br>
		<em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2021.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2110.08188">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://arxiv.org/abs/2106.14133">Generalized Few-Shot Semantic Segmentation</a><br>
		Xin Lai, <b>Zhuotao Tian*</b> Li Jiang, Shu Liu, Hengshuang Zhao, Liwei Wang, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2021</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2106.14133">Paper</a>]
		</p>
	</li>

	<li>
		<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.pdf">Homomorphic Latent Space Interpolation for Unpaired Image-To-Image Translation</a><br>
		Ying-Cong Chen, Xiaogang Xu, <b>Zhuotao Tian</b>, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR, Oral</b>), 2019</br>
		<p style="margin-top:3px">
			[<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.pdf">Paper</a>]
		</p>
	</li>

	<li>
		<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Learning_Shape-Aware_Embedding_for_Scene_Text_Detection_CVPR_2019_paper.pdf">Homomorphic Latent Space Interpolation for Unpaired Image-To-Image Translation</a><br>
		<b>Zhuotao Tian</b>, Michelle Shu, Pengyuan Lyu, Ruiyu Li, Chao Zhou, Xiaoyong Shen, Jiaya Jia <br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2019</br>
		<p style="margin-top:3px">
			[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Learning_Shape-Aware_Embedding_for_Scene_Text_Detection_CVPR_2019_paper.pdf">Paper</a>]
		</p>
	</li>
	
	
</ul>

<h2>Professional Activities</h2>
<ul>
	<li>Conference Reviewer/Program Committee:<br>
		&emsp; IEEE Conference on Computer Vision and Pattern Recognition (CVPR).<br>
		&emsp; IEEE International Conference on Computer Vision (ICCV).<br>
		&emsp; European Conference on Computer Vision (ECCV).<br>
		&emsp; Neural Information Processing Systems (NeurIPS).<br>
		&emsp; International Conference on Learning Representations (ICLR).<br>
		&emsp; International Conference on Machine Learning (ICML).<br>
		&emsp; ACM Multimedia (ACM-MM).<br>
	</li>
	<li>Journal Reviewer:<br>
		&emsp; IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).<br>
		&emsp; International Journal of Computer Vision (IJCV).<br>
		&emsp; IEEE Transactions on Image Processing (TIP).<br>
		&emsp; IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).<br>
		&emsp; IEEE Transactions on Neural Networks and Learning Systems (TNNLS).<br>
	</li>
	<li>Area Chair/Senior Program Committee:<br>
		&emsp; AAAI Conference on Artificial Intelligence (AAAI).<br>
		&emsp;  IEEE/CVF Winter Conference on Applications of Computer Vision (WACV).<br>
	</li>
</ul>


<h2>Teaching</h2>
<ul>
	<li>Teaching:
		<table id="Teaching" border="0" width="100%">
			<tbody>
				<tr>
					<td>ENGG 1100: Problem Solving by Programming</td>
				</tr>
				<tr>
					<td>ENGG 1110: Introduction to Engineering Design</td>
				</tr>
				<tr>
					<td>ENGG 2760: Probability for Engineers</td>
				</tr>
				<tr>
					<td>ENGG 5104: Image Processing and Computer Vision</td>
				</tr>
			</tbody>
		</table>
	</li>
</ul>

<!-- <div id="footer"> -->
	<!-- <div id="footer-text"></div>
	</div>
		<center>© Li Jiang | 2022</center>
	</div> -->

	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-88615920-1', 'auto');
	ga('send', 'pageview');

	</script>
<!-- </div> -->

<div id="cm" style="display: none;">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=EJGgXVNElphSoGp99mBvvA0EUD4cBLxcWb-YyZQBjro&cl=ffffff&w=a"></script>
</div>

</body>
</html>
